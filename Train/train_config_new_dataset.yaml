# Training Configuration for SmolVLA on New HDF5 Dataset
# =======================================================

# Random seed for reproducibility
seed: 1000

# Output directory for checkpoints and logs
output_dir: "outputs/train/smolvla_official_augmented"

# Dataset Configuration
# ---------------------
dataset:
  # Root directory containing HDF5 episode files
  root_dir: "/home/najo/NAS/VLA/dataset/New_dataset/collected_data/Red_point"

  # Option 1: Use all HDF5 files in root_dir (default)
  # If hdf5_files is not specified, all *.h5 files will be loaded

  # Action prediction horizon (1 for single-step, >1 for action chunks)
  horizon: 10            # Predict 10-step action chunks

  # State representation
  use_qpos: false        # Use joint positions (6 dims)
  use_ee_pose: true      # Use end-effector pose (6 dims) - default
  # Note: If both are true, state will be 12 dims (qpos + ee_pose)

  # Task instruction for VLA model
  task_instruction: "Insert needle into red point"

  # Data Augmentation
  # -----------------
  # Camera dropout for robustness to single/multi camera inputs
  camera_dropout_prob: 0.0  # DISABLED: No camera dropout
  min_cameras: 3            # Keep all 3 cameras active

  # Image augmentation
  # IMPORTANT: Color augmentation disabled to allow VLM to learn color-based features
  # (e.g., distinguishing red marker from screw holes)
  augment: true                  # ENABLED: Image augmentation to prevent overfitting
  augment_brightness: 0.10       # Max brightness change (±10%, reduced from 15%)
  augment_contrast: 0.10         # Max contrast change (±10%, reduced from 15%)
  augment_saturation: 0.0        # DISABLED: No saturation change (was ±15%)
  augment_hue: 0.0               # DISABLED: No hue shift (was ±10.8 degrees) - critical for color learning
  augment_noise: 0.01            # Gaussian noise std (1%)

# Policy Configuration
# --------------------
policy:
  # Path to downloaded pretrained model
  # This should be the path from Inference/lerobot_to_MECA.py
  # pretrained_model_path: "/home/irom/NAS/VLA/Insertion_VLAv4/sub_tasks/downloads/model"
  pretrained_model_path: "lerobot/smolvla_base"
  # Model configuration
  n_obs_steps: 1         # Number of observation steps
  chunk_size: 10         # Action chunk size (matches horizon)
  n_action_steps: 10     # Number of action steps to predict

  # Training strategy (SmolVLA official paper method)
  # Reference: "We train only the action expert module, keeping the VLM frozen"
  # Paper: https://arxiv.org/html/2506.01844v1
  freeze_vision_encoder: true   # Freeze vision encoder (part of VLM)
  train_expert_only: true       # Train action expert only, freeze VLM
  train_state_proj: true        # Train state projection layer

  # Action expert initialization strategy
  # If true, reset action expert to random weights (clean slate)
  # If false, use pretrained action expert weights from pretrained_model_path
  reset_action_expert: true     # ENABLED: Reset action expert for new task learning

  # Device configuration
  device: "cuda"                # "cuda" or "cpu"
  use_multi_gpu: false          # Use DataParallel for multi-GPU training

# Training Configuration
# ----------------------
training:
  # Training steps
  # NOTE: Quick training test with 25000 steps (~3.8 epochs)
  # Estimated time: ~3 hours (with 5 GPUs at 2.3 it/s)
  steps: 25000           # Total training steps (reduced for faster testing)

  # Batch size (increased with available memory)
  batch_size: 16        # Per-GPU batch size (effective=40 with 5 GPUs)

  # DataLoader settings
  shuffle: true          # Shuffle training data
  num_workers: 4         # Number of data loading workers
  pin_memory: true       # Pin memory for faster GPU transfer

  # Gradient clipping
  grad_clip_norm: 10.0   # Max gradient norm

  # Logging and saving
  log_freq: 100          # Log every N steps
  save_freq_epochs: 1.0  # Save checkpoint every N epochs (auto-calculates based on batch size)
  # Note: save_freq_epochs automatically adjusts when batch_size changes
  # Example: 1.0 = every epoch, 0.5 = twice per epoch, 2.0 = every 2 epochs

# Optimizer Configuration
# -----------------------
optimizer:
  lr: 0.0001             # Learning rate (1e-4)
  betas: [0.9, 0.95]     # Adam betas
  weight_decay: 0.00000000010    # Weight decay (1e-10)
  eps: 0.00000001        # Adam epsilon (1e-8)

# Scheduler Configuration
# -----------------------
scheduler:
  num_warmup_steps: 6541     # Warmup steps (1 epoch)
  num_decay_steps: 25000     # Decay steps (matches training steps)
  peak_lr: 0.0001            # Peak learning rate (1e-4, same as optimizer lr)
  decay_lr: 0.000001         # Final learning rate (1e-6)

# Notes:
# ------
# 1. Adjust batch_size based on your GPU memory (8 works for ~24GB VRAM)
# 2. If using multiple GPUs, set use_multi_gpu: true
# 3. Increase steps and decay_steps for longer training (e.g., 100000)
# 4. You can override these settings via command line:
#    python train_smolvla_new_dataset.py --config train_config_new_dataset.yaml --batch_size 4 --steps 100000
