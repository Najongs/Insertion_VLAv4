# Training Configuration for π0 (Pi Zero)
# ============================================
# π0 is Physical Intelligence's flow-matching VLA model
# Optimized for precise manipulation with visual-language conditioning

# Random seed for reproducibility
seed: 1000

# Output directory for checkpoints and logs
output_dir: "outputs/train/pi0_needle_insertion"

# Dataset Configuration
# ---------------------
dataset:
  # Root directory containing HDF5 episode files
  root_dir: "/home/najo/NAS/VLA/dataset/New_dataset/collected_data/Red_point"

  # Action prediction horizon (π0 uses action chunks)
  horizon: 50

  # State representation
  use_qpos: false        # Use joint positions (6 dims)
  use_ee_pose: true      # Use end-effector pose (6 dims) - default

  # Task instruction (π0 uses language conditioning)
  task_instruction: "Insert needle into red point"

  # Data Augmentation
  # -----------------
  augment: true
  augment_brightness: 0.15       # Max brightness change (±15%)
  augment_contrast: 0.15         # Max contrast change (±15%)
  augment_saturation: 0.10       # Saturation change (±10%)
  augment_hue: 0.05              # Hue shift (±18 degrees)
  augment_noise: 0.01            # Gaussian noise std (1%)

# Policy Configuration
# --------------------
policy:
  # π0 configuration
  pretrained_model_id: null  # No pretrained model for now

  # Observation and action
  n_obs_steps: 1         # Number of observation steps (π0 uses single observation)
  chunk_size: 50         # Action chunk size (action horizon)
  n_action_steps: 50     # Number of action steps to execute

  # Model architecture
  paligemma_variant: "gemma_2b"        # PaliGemma variant (gemma_300m or gemma_2b)
  action_expert_variant: "gemma_300m"  # Action expert variant
  dtype: "float32"                      # Data type (bfloat16 or float32)

  # Dimensions
  max_state_dim: 32      # Maximum state dimension (padded)
  max_action_dim: 32     # Maximum action dimension (padded)

  # Flow matching parameters
  num_inference_steps: 10              # Number of denoising steps
  time_sampling_beta_alpha: 1.5
  time_sampling_beta_beta: 1.0
  time_sampling_scale: 0.999
  time_sampling_offset: 0.001
  min_period: 0.004
  max_period: 4.0

  # Image resolution (π0 uses 224x224)
  image_resolution: [224, 224]

  # Training optimization
  gradient_checkpointing: false  # Enable for memory optimization
  compile_model: false           # Use torch.compile

# Training Configuration
# ----------------------
training:
  # Training steps
  steps: 30000           # 30k steps (π0 typical training length)

  # Batch size
  batch_size: 8          # Per-GPU batch size (effective=40 with 5 GPUs)

  # DataLoader settings
  shuffle: true
  num_workers: 4
  pin_memory: true

  # Logging and saving
  log_freq: 100          # Log every N steps
  save_freq_epochs: 1.0  # Save checkpoint every N epochs

# Optimizer Configuration
# -----------------------
optimizer:
  lr: 0.000025           # Learning rate (2.5e-5)
  betas: [0.9, 0.95]     # Adam betas
  weight_decay: 0.01     # Weight decay
  eps: 0.00000001        # Adam epsilon (1e-8)
  grad_clip_norm: 1.0    # Gradient clipping norm

# Scheduler Configuration
# -----------------------
scheduler:
  num_warmup_steps: 1000      # Warmup steps
  num_decay_steps: 30000      # Decay steps (matches training steps)
  peak_lr: 0.000025           # Peak learning rate (2.5e-5)
  decay_lr: 0.0000025         # Final learning rate (2.5e-6)

# Notes:
# ------
# 1. π0 uses flow matching (not diffusion) for action generation
# 2. Language conditioning enables better generalization
# 3. PaliGemma provides strong vision-language features
# 4. Supports multi-camera visual inputs
# 5. Action chunks enable smooth, temporally consistent actions
#
# Performance expectations:
# - π0 excels at generalization across tasks
# - Strong vision-language understanding
# - Smooth action generation via flow matching
# - Requires sufficient GPU memory (gemma_2b is large)
