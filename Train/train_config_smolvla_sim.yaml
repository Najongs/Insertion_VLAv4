# Training Configuration for SmolVLA on Simulation Data
# =====================================================================
# Adapted for training on Eye_trocar_sim dataset (collected with DR)
# - Domain Randomization (DR) already applied during data collection
# - No additional data augmentation needed
# - Can use higher learning rate due to consistent sim data

# Random seed for reproducibility
seed: 1000

# Output directory for checkpoints and logs
output_dir: "outputs/train/smolvla_needle_insertion_sim"

# Normalization Configuration
# ----------------------------
normalization:
  # Enable normalization (MEAN_STD for state and action)
  enable: true

  # Path to precomputed dataset statistics for simulation data
  # Run compute_dataset_stats.py on sim data first!
  stats_file: "dataset_stats_sim.yaml"

  # Normalization mode
  mode: "MEAN_STD"

# Dataset Configuration
# ---------------------
dataset:
  # Root directory containing simulation HDF5 episode files
  # Should point to Eye_trocar_sim folder with all sim subfolders
  root_dir: "/home/najo/NAS/VLA/dataset/New_dataset/collected_data/Eye_trocar/Eye_trocar_sim"

  # Action prediction horizon (SmolVLA paper: n=50)
  horizon: 50

  # State representation
  use_qpos: false        # Use joint positions (6 dims)
  use_ee_pose: true      # Use end-effector pose (6 dims)

  # Task instruction for simulation
  task_instruction: "Insert needle into eye trocar in simulation"

  # Data Augmentation: DISABLED for sim data (DR already applied during collection)
  # Simulation data was collected with:
  # - Background randomization
  # - Lighting randomization
  # - Camera jitter
  # - Geometry color randomization
  # - Image noise
  augment: false
  augment_brightness: 0.0
  augment_contrast: 0.0
  augment_saturation: 0.0
  augment_hue: 0.0
  augment_noise: 0.0

# Policy Configuration
# --------------------------------------
policy:
  # SmolVLA VLM backbone
  vlm_model_name: "HuggingFaceTB/SmolVLM2-500M-Video-Instruct"

  # Pretrained model path (if fine-tuning from real data model)
  pretrained_model_id: null  # Set to checkpoint path if transferring from real data

  # Observation and action
  n_obs_steps: 1         # Single observation
  chunk_size: 50         # Action chunk size
  n_action_steps: 50     # Number of action steps to execute

  # Dimensions
  max_state_dim: 32
  max_action_dim: 32

  # Flow matching parameters
  num_steps: 10

  # Image resolution
  resize_imgs_with_padding: [512, 512]

  # Tokenizer
  tokenizer_max_length: 48

  # Training optimization (train action expert only, VLM frozen)
  freeze_vision_encoder: true
  train_expert_only: true
  train_state_proj: true

  # VLM layers
  num_vlm_layers: 16

# Training Configuration
# --------------------------------------------------------
training:
  # Training steps
  # Simulation data is more consistent, so can converge faster
  # Start with 30k steps, adjust as needed
  steps: 30000

  # Batch size (adjust for your GPU memory)
  # With 5 GPUs: 16 per GPU = 80 total
  batch_size: 16

  # Gradient Accumulation
  gradient_accumulation_steps: 1

  # DataLoader settings
  num_workers: 0         # 0 for multi-GPU to avoid RAM issues
  pin_memory: true

  # Logging and saving
  log_freq: 100
  save_freq: 2000

  # Temporal consistency loss weight
  lambda_temporal: 0.1

  # Loss spike detection
  loss_spike_threshold: 10.0

  # Mixed Precision Training
  use_amp: false
  use_bfloat16: true

  # Torch optimizations
  use_torch_compile: false  # Set to true for faster training (requires PyTorch 2.0+)

# Validation Configuration
# -------------------------
validation:
  # Enable validation during training
  enable: true

  # Number of episodes to use for validation
  # With 352 total sim episodes, use ~5% for validation
  num_episodes: 20

  # Validation frequency (every N steps)
  val_freq: 2000

# Optimizer Configuration
# -----------------------------------------
optimizer:
  # Can use slightly higher LR for sim data due to consistency
  lr: 0.0001             # Peak learning rate: 1e-4
  betas: [0.9, 0.95]
  weight_decay: 0.0000000001  # 1e-10
  eps: 0.00000001        # 1e-8
  grad_clip_norm: 10.0

# Scheduler Configuration
# ----------------------------------------------------
scheduler:
  # Warmup steps (~3% of total steps)
  num_warmup_steps: 1000

  # Cosine decay
  num_decay_steps: 30000
  peak_lr: 0.0001        # 1e-4
  decay_lr: 0.0000025    # 2.5e-6

# W&B Configuration
# -----------------
wandb:
  enable: true
  project: "smolvla-meca500-insertion-sim"
  entity: null
  name: null
  tags:
    - "smolvla"
    - "simulation"
    - "domain-randomization"
    - "sim2real"
  notes: "SmolVLA training on simulation data with DR (352 episodes from Eye_trocar_sim)"

# Simulation Data Notes:
# ----------------------
# - Total: 352 episodes from Eye_trocar_sim subfolders
# - Data collected with Save_dataset_arg.py using domain randomization
# - DR applied during collection:
#   * Background images (random_backgrounds folder)
#   * Lighting randomization (position jitter)
#   * Camera jitter (position + rotation)
#   * Geometry color randomization
#   * Image Gaussian noise
#   * Sensor noise (qpos)
#   * Dynamics randomization (damping)
# - Camera names: side_camera, tool_camera, top_camera
# - State: ee_pose (6 dims) or qpos (6 dims)
# - Action: joint positions (6 dims)
#
# Training Strategy:
# ------------------
# 1. Train from scratch on sim data (this config)
# 2. Evaluate sim-trained model on real robot
# 3. If needed, fine-tune on small real dataset
# 4. Compare performance vs real-only training
#
# Expected Behavior:
# ------------------
# - Faster convergence than real data (more consistent)
# - Lower training loss (less noise)
# - Validation loss should be very close to training loss
# - Sim2real gap may require fine-tuning on real data
