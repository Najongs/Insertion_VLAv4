# Training Configuration for SmolVLA (Paper Settings + Normalization)
# =====================================================================
# Based on SmolVLA paper (Cadene et al., 2024) settings
# - MEAN_STD normalization for state and action
# - bfloat16 precision
# - torch.compile() optimization
# - AdamW optimizer with paper settings
# - Cosine learning rate schedule

# Random seed for reproducibility
seed: 1000

# Output directory for checkpoints and logs
output_dir: "outputs/train/smolvla_needle_insertion_normalized"

# Normalization Configuration
# ----------------------------
normalization:
  # Enable normalization (MEAN_STD for state and action)
  enable: true

  # Path to precomputed dataset statistics
  stats_file: "dataset_stats.yaml"

  # Normalization mode (MEAN_STD recommended by LeRobot)
  mode: "MEAN_STD"  # Options: MEAN_STD, MIN_MAX

# Dataset Configuration
# ---------------------
dataset:
  # Root directory containing HDF5 episode files
  root_dir: "/home/najo/NAS/VLA/dataset/New_dataset/collected_data/Eye_trocar"

  # Action prediction horizon (SmolVLA paper: n=50)
  horizon: 50

  # State representation
  use_qpos: false        # Use joint positions (6 dims)
  use_ee_pose: true      # Use end-effector pose (6 dims)

  # Task instruction (SmolVLA uses language conditioning)
  task_instruction: "Insert needle into eye trocar"

  # Data Augmentation (disabled for stability during initial training)
  augment: false
  augment_brightness: 0.15
  augment_contrast: 0.15
  augment_saturation: 0.10
  augment_hue: 0.05
  augment_noise: 0.01

# Policy Configuration (Paper Settings)
# --------------------------------------
policy:
  # SmolVLA VLM backbone (SmolVLM-2)
  vlm_model_name: "HuggingFaceTB/SmolVLM2-500M-Video-Instruct"

  # Pretrained model path (if fine-tuning)
  pretrained_model_id: "lerobot/smolvla_base"

  # Observation and action
  n_obs_steps: 1         # Single observation (paper default)
  chunk_size: 50         # Action chunk size (paper: n=50)
  n_action_steps: 50     # Number of action steps to execute

  # Dimensions
  max_state_dim: 32      # Maximum state dimension (padded)
  max_action_dim: 32     # Maximum action dimension (padded)

  # Flow matching parameters (paper: 10 steps during inference)
  num_steps: 10

  # Image resolution (paper: 512Ã—512)
  resize_imgs_with_padding: [512, 512]

  # Tokenizer
  tokenizer_max_length: 48

  # Training optimization (paper: train action expert only, VLM frozen)
  freeze_vision_encoder: true
  train_expert_only: true
  train_state_proj: true

  # VLM layers (paper: first 16 layers only)
  num_vlm_layers: 16


lora:
  # Enable LoRA (EXPERIMENTAL - may not work with SmolVLA)
  enable: false

  # LoRA rank (controls number of trainable parameters)
  # Higher rank = more parameters = better performance but more memory
  lora_r: 8              # Typical values: 4, 8, 16, 32

  # LoRA alpha (scaling factor)
  # Typically set to 2x the rank
  lora_alpha: 16         # Typical: 2 * lora_r

  # LoRA dropout (regularization)
  lora_dropout: 0.05     # Typical: 0.05-0.1

  # Target modules (which layers to apply LoRA)
  # Targeting attention and MLP layers for maximum impact
  target_modules:
    - "q_proj"           # Query projection
    - "v_proj"           # Value projection
    - "k_proj"           # Key projection
    - "o_proj"           # Output projection
    - "gate_proj"        # MLP gate projection
    - "up_proj"          # MLP up projection
    - "down_proj"        # MLP down projection


# Training Configuration (Paper Settings for Fine-tuning)
# --------------------------------------------------------
training:
  # Training steps (paper fine-tuning on real: 200k, but good results with fewer)
  steps: 10000

  # Batch size (paper fine-tuning: 64, adjust for your GPU memory)
  # With 5 GPUs: 8 per GPU = 40 total (reduce from paper's 64 for memory)
  batch_size: 16

  # Gradient Accumulation (to reach effective batch size closer to paper)
  # Effective batch = 8 * 5 GPUs * 2 = 80 (close to paper's 64)
  gradient_accumulation_steps: 1

  # DataLoader settings
  num_workers: 0         # 0 for multi-GPU to avoid RAM issues
  pin_memory: true

  # Logging and saving
  log_freq: 100
  save_freq: 1000

  # Temporal consistency loss weight
  lambda_temporal: 0.1

  # Loss spike detection (logs batches with abnormally high loss)
  loss_spike_threshold: 3.0  # Multiplier of moving average (e.g., 3.0 = log if loss > 3x avg)

  # Mixed Precision Training (paper: bfloat16)
  # Note: Use bfloat16 instead of float16 for better numerical stability
  use_amp: false         # Disabled, will use bfloat16 directly in policy
  use_bfloat16: true     # Paper optimization

  # Torch optimizations (paper: torch.compile)
  use_torch_compile: false  # Set to true for faster training (requires PyTorch 2.0+)

# Validation Configuration
# -------------------------
validation:
  # Enable validation during training
  enable: true

  # Number of episodes to use for validation
  num_episodes: 10

  # Validation frequency (every N steps)
  val_freq: 1000

# Optimizer Configuration (Paper Settings)
# -----------------------------------------
optimizer:
  # Paper: AdamW with Î²1=0.9, Î²2=0.95
  lr: 0.0001             # Peak learning rate: 1e-4
  betas: [0.9, 0.95]     # Paper betas
  weight_decay: 0.0000000001  # 1e-10
  eps: 0.00000001        # 1e-8
  grad_clip_norm: 10.0

# Scheduler Configuration (Paper: Cosine with warmup)
# ----------------------------------------------------
scheduler:
  # Paper: 100-step warmup for pretraining
  # For fine-tuning, use ~1% of total steps
  num_warmup_steps: 200

  # Cosine decay (paper: decay to 2.5e-6)
  num_decay_steps: 10000     # Matches training steps
  peak_lr: 0.0001            # 1e-4
  decay_lr: 0.0000025        # 2.5e-6 (paper minimum)

# W&B Configuration
# -----------------
wandb:
  enable: true
  project: "smolvla-meca500-insertion"
  entity: null
  name: null
  tags:
    - "smolvla"
    - "paper-settings"
    - "normalized"
    - "bfloat16"
  notes: "SmolVLA with paper settings and MEAN_STD normalization for state/action"

# Paper Optimizations Summary:
# ----------------------------
# âœ… Action chunk size: 50
# âœ… Flow matching steps: 10
# âœ… Image size: 512Ã—512
# âœ… VLM layers: 16
# âœ… Train action expert only, VLM frozen
# âœ… AdamW optimizer (Î²1=0.9, Î²2=0.95)
# âœ… Cosine LR schedule (1e-4 â†’ 2.5e-6)
# âœ… 100-step warmup
# âœ… MEAN_STD normalization (LeRobot standard)
# ðŸ”§ bfloat16 precision (applied in policy)
# ðŸ”§ torch.compile() (optional, requires PyTorch 2.0+)
#
# Fine-tuning Notes:
# - Paper uses 200k steps for real-world tasks
# - Good results achieved with fewer steps in practice
# - Start with 10k steps, increase if needed
#
# Multi-GPU Training:
# - Paper pretraining: 4 GPUs with batch size 256
# - Can train on single GPU due to small model size
# - Our setup: 5 GPUs, batch 8 per GPU, grad accum 2 = effective batch 80
