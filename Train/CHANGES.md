# Training Script Changes - VLM Full Training

## ğŸ¯ ë¬¸ì œì 
ì´ì „ í•™ìŠµì—ì„œëŠ” **Expertë§Œ í•™ìŠµ**ë˜ì—ˆê³  **VLM(Vision-Language Model)ì´ freeze**ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤.
- í•™ìŠµëœ íŒŒë¼ë¯¸í„°: 155/500 (31%)
- VLMì´ "ë‚˜ì‚¬ êµ¬ë© vs ë¹¨ê°„ ë§ˆì»¤"ë¥¼ êµ¬ë³„í•˜ì§€ ëª»í•¨
- Pretrained VLMì€ ì¼ë°˜ ì´ë¯¸ì§€ë¡œë§Œ í•™ìŠµë˜ì–´ ë„ë©”ì¸ íŠ¹í™” featureë¥¼ í•™ìŠµí•˜ì§€ ëª»í•¨

## âœ… í•´ê²° ë°©ë²•

### 1. **ëª¨ë“  íŒŒë¼ë¯¸í„° ëª…ì‹œì  Unfreeze** (train_smolvla_new_dataset.py)
```python
# Policy ë¡œë“œ í›„ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € unfreeze
for param in policy.parameters():
    param.requires_grad = True
```

**ë³€ê²½ ì „:**
- Pretrained model ë¡œë“œ ì‹œ ì¼ë¶€ íŒŒë¼ë¯¸í„°ê°€ ì´ë¯¸ freezeë˜ì–´ ìˆì—ˆìŒ
- Freeze ì„¤ì •ì´ ì œëŒ€ë¡œ ì ìš©ë˜ì§€ ì•ŠìŒ

**ë³€ê²½ í›„:**
- ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ trainableë¡œ ì„¤ì •
- Freeze ì„¤ì •ì˜ defaultë¥¼ `False`ë¡œ ë³€ê²½
- í•™ìŠµ ì‹œì‘ ì „/í›„ trainable params ì¹´ìš´íŠ¸ ë¡œê·¸ ì¶”ê°€

### 2. **Color Augmentation ì œê±°** (train_config_new_dataset.yaml)
```yaml
augment_saturation: 0.0  # ë¹„í™œì„±í™” (was 0.15)
augment_hue: 0.0         # ë¹„í™œì„±í™” (was 0.03) - ìƒ‰ìƒ í•™ìŠµì— ì¤‘ìš”!
```

**ì´ìœ :**
- Hue augmentationì´ ë¹¨ê°„ìƒ‰ì„ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ ë³€í™˜
- VLMì´ ìƒ‰ìƒ ê¸°ë°˜ featureë¥¼ í•™ìŠµí•˜ì§€ ëª»í•¨
- "ë¹¨ê°„ ë§ˆì»¤" vs "íšŒìƒ‰ ë‚˜ì‚¬ êµ¬ë©" êµ¬ë³„ ë¶ˆê°€ëŠ¥

### 3. **í•™ìŠµ ê¸°ê°„ ì¦ê°€**
```yaml
steps: 170830  # 10 epochs (ì´ì „: 85415 = 5 epochs)
```

**ì´ìœ :**
- VLM fine-tuningì€ Expertë§Œ í•™ìŠµí•˜ëŠ” ê²ƒë³´ë‹¤ ì˜¤ë˜ ê±¸ë¦¼
- Pretrained weightsì˜ ê´€ì„± ê·¹ë³µ í•„ìš”
- ìƒˆë¡œìš´ ë„ë©”ì¸ í•™ìŠµ ì‹œê°„ í™•ë³´

### 4. **Trainable Parameters Logging**
```python
logger.info(f"After unfreezing: {initial_trainable:,} / {initial_total:,} params trainable")
logger.info(f"After freeze settings: {final_trainable:,} / {initial_total:,} params trainable")
```

**íš¨ê³¼:**
- í•™ìŠµ ì‹œì‘ ì‹œ ëª‡ ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ì‹¤ì œë¡œ í•™ìŠµë˜ëŠ”ì§€ í™•ì¸ ê°€ëŠ¥
- ì´ì „ í•™ìŠµì—ì„œëŠ” ì´ ì •ë³´ê°€ ì—†ì–´ì„œ ë¬¸ì œë¥¼ ë°œê²¬í•˜ê¸° ì–´ë ¤ì› ìŒ

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### ì´ì „ í•™ìŠµ:
```
VLM (vision-language model): 345 params  âŒ FROZEN
LM Expert (action expert): 145 params    âœ“ í•™ìŠµë¨
Action/State projection: 10 params       âœ“ í•™ìŠµë¨
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total trained: 155/500 params (31%)
```

### ìƒˆë¡œìš´ í•™ìŠµ:
```
VLM (vision-language model): 345 params  âœ“ í•™ìŠµë¨
LM Expert (action expert): 145 params    âœ“ í•™ìŠµë¨
Action/State projection: 10 params       âœ“ í•™ìŠµë¨
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total trained: 500/500 params (100%)
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### Multi-GPU í•™ìŠµ:
```bash
bash train_multi_gpu.sh
```

### Single GPU í•™ìŠµ:
```bash
bash train_single_gpu.sh
```

### í•™ìŠµ ì‹œì‘ ì‹œ í™•ì¸ì‚¬í•­:
1. ë¡œê·¸ì—ì„œ "After unfreezing" ë©”ì‹œì§€ í™•ì¸
2. Trainable paramsê°€ 500ê°œ ê·¼ì²˜ì¸ì§€ í™•ì¸ (155ê°€ ì•„ë‹˜!)
3. "VLM frozen" ë©”ì‹œì§€ê°€ **ì¶œë ¥ë˜ì§€ ì•Šì•„ì•¼** í•¨

## ğŸ“ Config ìš”ì•½

### Policy Settings:
```yaml
freeze_vision_encoder: false  # Vision encoder í•™ìŠµ
train_expert_only: false      # VLM ì „ì²´ í•™ìŠµ
train_state_proj: false       # ëª¨ë“  ë ˆì´ì–´ í•™ìŠµ
```

### Augmentation Settings:
```yaml
augment_brightness: 0.10     # Â±10% (reduced from 15%)
augment_contrast: 0.10       # Â±10% (reduced from 15%)
augment_saturation: 0.0      # DISABLED (was 15%)
augment_hue: 0.0             # DISABLED (was 3%) - critical!
```

### Training Settings:
```yaml
steps: 170830                # 10 epochs
batch_size: 1                # MUST be 1
lr: 0.0001                   # Learning rate
```

## ğŸ“ ê³µì‹ LeRobot íŒ¨í„´ ì ìš©

ì´ ìˆ˜ì •ì‚¬í•­ì€ ê³µì‹ LeRobot í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì˜ íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤:
1. **ëª…ì‹œì  íŒŒë¼ë¯¸í„° ê´€ë¦¬**: ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € unfreeze
2. **Logging**: Trainable params ì¹´ìš´íŠ¸ ë¡œê·¸
3. **ì •í™•í•œ freeze ì œì–´**: Defaultë¥¼ Falseë¡œ ì„¤ì •

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **í•™ìŠµ ì‹œê°„**: 10 epochsëŠ” ì•½ **48ì‹œê°„** ì†Œìš” (ì´ì „ì˜ 2ë°°)
2. **ë©”ëª¨ë¦¬**: VLM ì „ì²´ í•™ìŠµìœ¼ë¡œ ì¸í•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ê°€ëŠ¥
3. **ì²« í•™ìŠµ ì‹œ**: ë¡œê·¸ë¥¼ ì£¼ì˜ ê¹Šê²Œ í™•ì¸í•˜ì—¬ ì‹¤ì œë¡œ 500ê°œ íŒŒë¼ë¯¸í„°ê°€ í•™ìŠµë˜ëŠ”ì§€ í™•ì¸

## ğŸ” í•™ìŠµ ì§„í–‰ ì¤‘ í™•ì¸

```bash
# ë¡œê·¸ì—ì„œ trainable params í™•ì¸
grep "trainable" outputs/train/smolvla_new_dataset_multigpu/logs/train_*.log

# ì²´í¬í¬ì¸íŠ¸ì—ì„œ í™•ì¸
python3 -c "
import torch
ckpt = torch.load('outputs/train/smolvla_new_dataset_multigpu/checkpoints/checkpoint_latest.pt', map_location='cpu')
optimizer_state = ckpt.get('optimizer_state_dict', {})
print(f'Parameters in optimizer: {len(optimizer_state.get(\"state\", {}))}')
"
```

ê¸°ëŒ€ ì¶œë ¥: **500ê°œ ê·¼ì²˜** (155ê°€ ì•„ë‹˜!)
