import h5py
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import sys

def save_sensor_plots(force_data, aline_data, output_path):
    """ì„¼ì„œ ë°ì´í„°(Force + A-line) ì‹œê°í™”ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥"""
    print(f"ğŸ“Š ì„¼ì„œ ë°ì´í„° ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: {output_path}")
    print(f"  Force shape: {force_data.shape}, A-line shape: {aline_data.shape}")

    fig, axes = plt.subplots(2, 1, figsize=(14, 10), gridspec_kw={'height_ratios': [1, 2]})

    # 1. Force ë°ì´í„° (ì‹œê³„ì—´)
    ax1 = axes[0]
    ax1.plot(force_data, linewidth=1.5, color='red')
    ax1.set_title('Force Sensor Data (FPI)', fontsize=12, weight='bold')
    ax1.set_xlabel('Time Steps')
    ax1.set_ylabel('Force (N)')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(0, color='black', linewidth=0.5, linestyle='--')

    # í†µê³„ ì •ë³´ ì¶”ê°€
    force_stats = f"Min: {force_data.min():.3f}, Max: {force_data.max():.3f}, Mean: {force_data.mean():.3f}, Std: {force_data.std():.3f}"
    ax1.text(0.02, 0.98, force_stats, transform=ax1.transAxes,
             fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # 2. A-line ë°ì´í„° (M-mode ì´ë¯¸ì§€)
    ax2 = axes[1]
    # Transpose: (ì‹œê°„, 1025) â†’ (1025, ì‹œê°„) for correct display
    im = ax2.imshow(aline_data.T, aspect='auto', cmap='gray', interpolation='nearest')
    ax2.set_title('OCT A-scan Data (M-mode Image)', fontsize=12, weight='bold')
    ax2.set_xlabel('Time Steps')
    ax2.set_ylabel('Depth Pixels (A-scan)')
    cbar = fig.colorbar(im, ax=ax2, label='Intensity')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… ì„¼ì„œ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")


def save_plots(actions, qpos, ee_pose, output_path):
    """ë°ì´í„° ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥"""
    print(f"ğŸ“Š ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤: {output_path}")

    # ë°ì´í„° ê²€ì¦
    qpos_valid = np.any(np.abs(qpos) > 0.001)
    ee_pose_valid = np.any(np.abs(ee_pose) > 0.001)

    if not qpos_valid:
        print("âš ï¸  WARNING: qpos (joint positions) is all zeros! Robot data may not have been recorded.")
    if not ee_pose_valid:
        print("âš ï¸  WARNING: ee_pose (end-effector pose) is all zeros! Robot data may not have been recorded.")

    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“ˆ Data Statistics:")
    print(f"  Actions:  min={actions.min():.3f}, max={actions.max():.3f}, mean={actions.mean():.3f}")
    print(f"  Qpos:     min={qpos.min():.3f}, max={qpos.max():.3f}, std={qpos.std():.3f}")
    print(f"  EE Pose:  min={ee_pose.min():.3f}, max={ee_pose.max():.3f}, std={ee_pose.std():.3f}")
    print(f"  EE Position (XYZ):    min={ee_pose[:, :3].min():.3f}, max={ee_pose[:, :3].max():.3f}")
    print(f"  EE Orientation (RPY): min={ee_pose[:, 3:].min():.3f}, max={ee_pose[:, 3:].max():.3f}")

    fig, axes = plt.subplots(4, 1, figsize=(14, 16))

    # 1. Action (ëª…ë ¹) - 6ì¶• ëª¨ë‘ í™•ì¸
    ax1 = axes[0]
    title_suffix = " [OK]" if np.any(np.abs(actions) > 0.001) else " [No data]"
    ax1.set_title("1. Joystick Actions (Command)" + title_suffix, fontsize=12, weight='bold')
    ax1.plot(actions[:, 0], label='X (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    ax1.plot(actions[:, 1], label='Y (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    ax1.plot(actions[:, 2], label='Z (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    ax1.plot(actions[:, 3], label='Rx (Pitch)', linewidth=2)
    ax1.plot(actions[:, 4], label='Ry (Roll)', linewidth=2)
    ax1.plot(actions[:, 5], label='Rz (Yaw)', linewidth=2)
    ax1.legend(loc='upper right', ncol=3, fontsize=9)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylabel("Command Value")

    # 2. Joint Positions (ê´€ì ˆ) - 6ê°œ ê´€ì ˆ í™•ì¸
    ax2 = axes[1]
    title_suffix = " [OK]" if qpos_valid else " [ERROR - All zeros]"
    ax2.set_title("2. Joint Positions (J1 ~ J6)" + title_suffix, fontsize=12, weight='bold')
    colors = ['r', 'g', 'b', 'c', 'm', 'y']
    for i in range(6):
        ax2.plot(qpos[:, i], label=f'Joint {i+1}', color=colors[i], linewidth=1.5)
    ax2.legend(loc='upper right', ncol=3, fontsize=9)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylabel("Degrees")

    # 3. End-Effector Position (ìœ„ì¹˜: X, Y, Z)
    ax3 = axes[2]
    title_suffix = " [OK]" if ee_pose_valid else " [ERROR - All zeros]"
    ax3.set_title("3. End-Effector Position (X, Y, Z)" + title_suffix, fontsize=12, weight='bold')
    ax3.plot(ee_pose[:, 0], label='X (mm)', color='r', linewidth=2)
    ax3.plot(ee_pose[:, 1], label='Y (mm)', color='g', linewidth=2)
    ax3.plot(ee_pose[:, 2], label='Z (mm)', color='b', linewidth=2)
    ax3.legend(loc='upper right', fontsize=9)
    ax3.grid(True, alpha=0.3)
    ax3.set_ylabel("Position (mm)")

    # 4. End-Effector Orientation (íšŒì „: Rx, Ry, Rz)
    ax4 = axes[3]
    title_suffix = " [OK]" if ee_pose_valid else " [ERROR - All zeros]"
    ax4.set_title("4. End-Effector Orientation (Rx, Ry, Rz)" + title_suffix, fontsize=12, weight='bold')
    ax4.plot(ee_pose[:, 3], label='Rx (Alpha)', color='c', linewidth=2)
    ax4.plot(ee_pose[:, 4], label='Ry (Beta)', color='m', linewidth=2)
    ax4.plot(ee_pose[:, 5], label='Rz (Gamma)', color='y', linewidth=2)
    ax4.legend(loc='upper right', fontsize=9)
    ax4.grid(True, alpha=0.3)
    ax4.set_ylabel("Orientation (degrees)")
    ax4.set_xlabel("Time Steps")

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")


def save_video_and_plots(file_path, output_dir=None):
    """ë°ì´í„°ì…‹ì˜ ì˜ìƒê³¼ ê·¸ë˜í”„ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    print(f"ğŸ“‚ Loading Dataset: {file_path}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = Path(file_path).parent / "saved_outputs"
    else:
        output_dir = Path(output_dir)

    output_dir.mkdir(exist_ok=True)

    # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    dataset_name = Path(file_path).stem
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"{dataset_name}_{timestamp}"

    video_path = output_dir / f"{base_name}_video.mp4"
    plot_path = output_dir / f"{base_name}_plots.png"
    sensor_plot_path = output_dir / f"{base_name}_sensor.png"

    try:
        with h5py.File(file_path, 'r') as f:
            # --- 1. ë°ì´í„° ë¡œë“œ ---
            images_grp = f['observations/images']
            qpos = f['observations/qpos'][:]
            actions = f['action'][:]

            # EE Poseê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë¡œë“œ
            if 'observations/ee_pose' in f:
                ee_pose = f['observations/ee_pose'][:]
            else:
                ee_pose = np.zeros_like(qpos)

            # ì„¼ì„œ ë°ì´í„° ë¡œë“œ (ìˆëŠ” ê²½ìš°)
            has_sensor = 'observations/sensor' in f
            if has_sensor:
                sensor_grp = f['observations/sensor']
                force_data = sensor_grp['force'][:]
                aline_data = sensor_grp['aline'][:]
                print(f"âœ… ì„¼ì„œ ë°ì´í„° ë°œê²¬: Force {force_data.shape}, A-line {aline_data.shape}")
            else:
                force_data = None
                aline_data = None
                print(f"âš ï¸ ì„¼ì„œ ë°ì´í„° ì—†ìŒ")

            cam_keys = sorted(list(images_grp.keys()))
            total_steps = len(actions)
            print(f"ğŸ“· Cameras: {cam_keys}")
            print(f"â±ï¸ Total Steps: {total_steps}")

            # ì˜ìƒ ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë“œ
            print("ğŸ“¥ Loading video frames to memory...")
            video_streams = {}
            for cam in cam_keys:
                video_streams[cam] = images_grp[cam][:]

            # --- 2. ë¹„ë””ì˜¤ ì €ì¥ ---
            print(f"\nğŸ¬ ë¹„ë””ì˜¤ë¥¼ ì €ì¥í•©ë‹ˆë‹¤: {video_path}")

            # ì²« í”„ë ˆì„ìœ¼ë¡œ ë¹„ë””ì˜¤ ì„¤ì • ì´ˆê¸°í™”
            first_frames = []
            for cam in cam_keys:
                frame = cv2.cvtColor(video_streams[cam][0], cv2.COLOR_RGB2BGR)
                first_frames.append(frame)

            combined_sample = np.hstack(first_frames)
            h, w, _ = combined_sample.shape
            info_board_height = 100
            total_height = h + info_board_height

            # í•´ìƒë„ ì¡°ì • (ë„ˆë¬´ í¬ë©´ ì¤„ì´ê¸°)
            scale = 1.0
            if w > 1920:
                scale = 0.6
                w = int(w * scale)
                total_height = int(total_height * scale)

            # VideoWriter ì´ˆê¸°í™”
            # FPS ì„¤ì •: Robot_action.pyì˜ CONTROL_FREQUENCYì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
            fps = 15  # ë°ì´í„° ìˆ˜ì§‘ FPSì™€ ë™ì¼ (Robot_action.py:32)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(video_path), fourcc, fps, (w, total_height))
            print(f"  FPS ì„¤ì •: {fps}")

            # ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬
            for i in range(total_steps):
                if i % 50 == 0:
                    print(f"  Progress: {i}/{total_steps} frames")

                frames = []
                for cam in cam_keys:
                    frame = cv2.cvtColor(video_streams[cam][i], cv2.COLOR_RGB2BGR)
                    cv2.putText(frame, f"{cam}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    frames.append(frame)

                # í™”ë©´ ë³‘í•©
                combined_img = np.hstack(frames)

                # ì •ë³´ì°½ (Info Board)
                h_orig, w_orig, _ = combined_img.shape
                info_board = np.zeros((info_board_height, w_orig, 3), dtype=np.uint8)

                # í˜„ì¬ ìƒíƒœ í…ìŠ¤íŠ¸
                curr_act = actions[i]
                curr_q = qpos[i]

                txt1 = f"Step: {i}/{total_steps}"
                txt2 = f"Act(Move): {curr_act[:3].round(2)} | Act(Rot): {curr_act[3:].round(2)}"
                txt3 = f"Joints: {curr_q.round(1)}"

                cv2.putText(info_board, txt1, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(info_board, txt2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(info_board, txt3, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)

                display = np.vstack([combined_img, info_board])

                # í•´ìƒë„ ì¡°ì •
                if scale < 1.0:
                    display = cv2.resize(display, (w, total_height))

                out.write(display)

            out.release()
            print(f"âœ… ë¹„ë””ì˜¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {video_path}")

            # --- 3. ê·¸ë˜í”„ ì €ì¥ ---
            save_plots(actions, qpos, ee_pose, plot_path)

            # --- 4. ì„¼ì„œ ë°ì´í„° ê·¸ë˜í”„ ì €ì¥ (ìˆëŠ” ê²½ìš°) ---
            if has_sensor and force_data is not None and aline_data is not None:
                save_sensor_plots(force_data, aline_data, sensor_plot_path)

            print(f"\nğŸ‰ ëª¨ë“  íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"  ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
            print(f"  ğŸ¬ ë¹„ë””ì˜¤: {video_path.name}")
            print(f"  ğŸ“Š ê·¸ë˜í”„: {plot_path.name}")
            if has_sensor:
                print(f"  ğŸ“Š ì„¼ì„œ ê·¸ë˜í”„: {sensor_plot_path.name}")

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


def visualize_sensor_data(npz_file):
    """
    .npz íŒŒì¼ì— ì €ì¥ëœ ì„¼ì„œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

    - force ë°ì´í„°ëŠ” ì„  ê·¸ë˜í”„ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    - aline (fpi) ë°ì´í„°ëŠ” 2D ì´ë¯¸ì§€ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    try:
        # ë°ì´í„° ë¡œë“œ
        data_npz = np.load(npz_file)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {npz_file}")
        return

    # 'forces'ì™€ 'alines' í‚¤ í™•ì¸
    if 'forces' not in data_npz or 'alines' not in data_npz:
        print(f"ì˜¤ë¥˜: '{npz_file}' íŒŒì¼ì— 'forces' ë˜ëŠ” 'alines' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(data_npz.keys())}")
        return

    force_data = data_npz['forces']
    aline_data = data_npz['alines']
    print(f"Force ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. í˜•íƒœ: {force_data.shape}")
    print(f"Aline ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. í˜•íƒœ: {aline_data.shape}")

    # ì‹œê°í™”
    fig, axs = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [1, 3]})
    
    # íŒŒì¼ëª…ì„ ì œëª©ì— ì¶”ê°€
    base_filename = os.path.basename(npz_file)
    fig.suptitle(f'Sensor Data Visualization\n({base_filename})', fontsize=16)

    # Force ë°ì´í„° í”Œë¡¯
    axs[0].plot(force_data)
    axs[0].set_title('Force Data')
    axs[0].set_xlabel('Time step')
    axs[0].set_ylabel('Force')
    axs[0].grid(True)

    # Aline (FPI) ë°ì´í„° í”Œë¡¯ (ì´ë¯¸ì§€)
    im = axs[1].imshow(aline_data.T, aspect='auto', cmap='gray', interpolation='none')
    axs[1].set_title('Aline (FPI) Data')
    axs[1].set_xlabel('Time step')
    axs[1].set_ylabel('FPI sensor index')
    fig.colorbar(im, ax=axs[1], label='Sensor Reading')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    
    # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
    output_filename = 'sensor_data_visualization.png'
    plt.savefig(output_filename)
    print(f"ì‹œê°í™” ê²°ê³¼ë¥¼ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    plt.close()

if __name__ == "__main__":
    if len(sys.argv) > 1:
        npz_file_path = sys.argv[1]
        visualize_sensor_data(npz_file_path)
    else:
        print("ì‚¬ìš©ë²•: python visualize_sensor.py <.npz íŒŒì¼ ê²½ë¡œ>")



if __name__ == "__main__":
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ìë™ ë¡œë“œ
    dataset_dir = Path("./collected_data")
    files = sorted(dataset_dir.glob("*.h5"), key=lambda f: f.stat().st_mtime, reverse=True)

    if not files:
        print("âš ï¸ No dataset files (.h5) found!")
    else:
        print(f"ğŸ“Œ ì²˜ë¦¬í•  íŒŒì¼: {files[0].name}")
        save_video_and_plots(files[0])
