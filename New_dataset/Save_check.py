import h5py
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def plot_detailed_data(actions, qpos, ee_pose):
    """ë°ì´í„° ì¬ìƒì´ ëë‚˜ë©´ ì‹¤í–‰ë˜ëŠ” ìƒì„¸ ê·¸ë˜í”„ í•¨ìˆ˜"""
    print("ğŸ“Š ìƒì„¸ ë°ì´í„° ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")

    # ë°ì´í„° ê²€ì¦
    qpos_valid = np.any(np.abs(qpos) > 0.001)
    ee_pose_valid = np.any(np.abs(ee_pose) > 0.001)

    if not qpos_valid:
        print("âš ï¸  WARNING: qpos (joint positions) is all zeros! Robot data may not have been recorded.")
    if not ee_pose_valid:
        print("âš ï¸  WARNING: ee_pose (end-effector pose) is all zeros! Robot data may not have been recorded.")

    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“ˆ Data Statistics:")
    print(f"  Actions:  min={actions.min():.3f}, max={actions.max():.3f}, mean={actions.mean():.3f}")
    print(f"  Qpos:     min={qpos.min():.3f}, max={qpos.max():.3f}, std={qpos.std():.3f}")
    print(f"  EE Pose:  min={ee_pose.min():.3f}, max={ee_pose.max():.3f}, std={ee_pose.std():.3f}")
    print(f"  EE Position (XYZ):    min={ee_pose[:, :3].min():.3f}, max={ee_pose[:, :3].max():.3f}")
    print(f"  EE Orientation (RPY): min={ee_pose[:, 3:].min():.3f}, max={ee_pose[:, 3:].max():.3f}")

    fig, axes = plt.subplots(4, 1, figsize=(14, 16))

    # 1. Action (ëª…ë ¹) - 6ì¶• ëª¨ë‘ í™•ì¸
    ax1 = axes[0]
    title_suffix = " [OK]" if np.any(np.abs(actions) > 0.001) else " [No data]"
    ax1.set_title("1. Joystick Actions (Command)" + title_suffix, fontsize=12, weight='bold')
    # ì´ë™(XYZ)ì€ ì ì„ ìœ¼ë¡œ íë¦¬ê²Œ
    ax1.plot(actions[:, 0], label='X (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    ax1.plot(actions[:, 1], label='Y (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    ax1.plot(actions[:, 2], label='Z (Vel)', linestyle='--', alpha=0.6, linewidth=1.5)
    # íšŒì „(RxRyRz)ì€ ì‹¤ì„ ìœ¼ë¡œ ì§„í•˜ê²Œ (ì¤‘ì  í™•ì¸)
    ax1.plot(actions[:, 3], label='Rx (Pitch)', linewidth=2)
    ax1.plot(actions[:, 4], label='Ry (Roll)', linewidth=2)
    ax1.plot(actions[:, 5], label='Rz (Yaw)', linewidth=2)
    ax1.legend(loc='upper right', ncol=3, fontsize=9)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylabel("Command Value")

    # 2. Joint Positions (ê´€ì ˆ) - 6ê°œ ê´€ì ˆ í™•ì¸
    ax2 = axes[1]
    title_suffix = " [OK]" if qpos_valid else " [ERROR - All zeros]"
    ax2.set_title("2. Joint Positions (J1 ~ J6)" + title_suffix, fontsize=12, weight='bold')
    colors = ['r', 'g', 'b', 'c', 'm', 'y']
    for i in range(6):
        ax2.plot(qpos[:, i], label=f'Joint {i+1}', color=colors[i], linewidth=1.5)
    ax2.legend(loc='upper right', ncol=3, fontsize=9)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylabel("Degrees")

    # 3. End-Effector Position (ìœ„ì¹˜: X, Y, Z)
    ax3 = axes[2]
    title_suffix = " [OK]" if ee_pose_valid else " [ERROR - All zeros]"
    ax3.set_title("3. End-Effector Position (X, Y, Z)" + title_suffix, fontsize=12, weight='bold')
    ax3.plot(ee_pose[:, 0], label='X (mm)', color='r', linewidth=2)
    ax3.plot(ee_pose[:, 1], label='Y (mm)', color='g', linewidth=2)
    ax3.plot(ee_pose[:, 2], label='Z (mm)', color='b', linewidth=2)
    ax3.legend(loc='upper right', fontsize=9)
    ax3.grid(True, alpha=0.3)
    ax3.set_ylabel("Position (mm)")

    # 4. End-Effector Orientation (íšŒì „: Rx, Ry, Rz)
    ax4 = axes[3]
    title_suffix = " [OK]" if ee_pose_valid else " [ERROR - All zeros]"
    ax4.set_title("4. End-Effector Orientation (Rx, Ry, Rz)" + title_suffix, fontsize=12, weight='bold')
    ax4.plot(ee_pose[:, 3], label='Rx (Alpha)', color='c', linewidth=2)
    ax4.plot(ee_pose[:, 4], label='Ry (Beta)', color='m', linewidth=2)
    ax4.plot(ee_pose[:, 5], label='Rz (Gamma)', color='y', linewidth=2)
    ax4.legend(loc='upper right', fontsize=9)
    ax4.grid(True, alpha=0.3)
    ax4.set_ylabel("Orientation (degrees)")
    ax4.set_xlabel("Time Steps")

    plt.tight_layout()
    plt.show()

def play_and_inspect(file_path):
    print(f"ğŸ“‚ Loading Dataset: {file_path}")
    
    try:
        with h5py.File(file_path, 'r') as f:
            # --- 1. ë°ì´í„° ë¡œë“œ ---
            images_grp = f['observations/images']
            qpos = f['observations/qpos'][:]
            actions = f['action'][:]
            # EE Poseê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë¡œë“œ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€)
            if 'observations/ee_pose' in f:
                ee_pose = f['observations/ee_pose'][:]
            else:
                ee_pose = np.zeros_like(qpos)

            cam_keys = sorted(list(images_grp.keys()))
            total_steps = len(actions)
            print(f"ğŸ“· Cameras: {cam_keys}")
            print(f"â±ï¸ Total Steps: {total_steps}")

            # ì˜ìƒ ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë“œ
            # âœ¨ ìë™ í˜•ì‹ ê°ì§€ (JPEG / GZIP ëª¨ë‘ ì§€ì›)
            video_streams = {}

            # ì²« ë²ˆì§¸ ì¹´ë©”ë¼ë¡œ í˜•ì‹ í™•ì¸
            first_cam = cam_keys[0]
            first_dataset = images_grp[first_cam]

            # ì‹¤ì œ ë°ì´í„°ë¥¼ ì½ì–´ì„œ í˜•ì‹ ê°ì§€ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
            is_jpeg_format = False
            try:
                # ì²« ë²ˆì§¸ í”„ë ˆì„ ìƒ˜í”Œ ì½ê¸°
                sample = first_dataset[0]

                if isinstance(sample, np.ndarray):
                    # shapeê°€ (H, W, 3)ì´ë©´ GZIP (ì´ë¯¸ ë””ì½”ë”©ëœ ì´ë¯¸ì§€)
                    if len(sample.shape) == 3 and sample.shape[2] == 3:
                        is_jpeg_format = False
                        print(f"   ğŸ’¡ Sample shape: {sample.shape} â†’ GZIP format detected")
                    # shapeê°€ (N,)ì´ê³  dtypeì´ uint8ì´ë©´ JPEG (ì••ì¶•ëœ ë°”ì´ë„ˆë¦¬)
                    elif len(sample.shape) == 1 and sample.dtype == np.uint8:
                        is_jpeg_format = True
                        print(f"   ğŸ’¡ Sample shape: {sample.shape} â†’ JPEG format detected")
                    else:
                        # ê¸°íƒ€ ê²½ìš°: dataset shapeë¡œ íŒë‹¨
                        is_jpeg_format = len(first_dataset.shape) != 4
                else:
                    # numpy arrayê°€ ì•„ë‹ˆë©´ JPEGì¼ ê°€ëŠ¥ì„±
                    is_jpeg_format = True
            except Exception as e:
                print(f"   âš ï¸ Format detection failed: {e}, falling back to shape check")
                # Fallback: dataset shapeë¡œ íŒë‹¨
                is_jpeg_format = len(first_dataset.shape) != 4

            if is_jpeg_format:
                print("ğŸ”„ Detected JPEG compression format - Decoding frames...")
                for cam in cam_keys:
                    dataset = images_grp[cam]
                    decoded_frames = []
                    decode_failures = 0

                    # í”„ë ˆì„ ìˆ˜ í™•ì¸
                    num_frames = len(dataset)

                    for idx in range(num_frames):
                        try:
                            # HDF5 vlen dtype ì½ê¸° (ê° ìš”ì†Œ ê°œë³„ ì ‘ê·¼)
                            jpeg_buf = dataset[idx]

                            # ë””ë²„ê¹…: ì²« í”„ë ˆì„ ì •ë³´ ì¶œë ¥
                            if idx == 0 and decode_failures == 0:
                                print(f"   ğŸ” Debug {cam} frame 0: type={type(jpeg_buf)}, ", end="")
                                if isinstance(jpeg_buf, np.ndarray):
                                    print(f"shape={jpeg_buf.shape}, dtype={jpeg_buf.dtype}")
                                else:
                                    print(f"len={len(jpeg_buf) if hasattr(jpeg_buf, '__len__') else 'N/A'}")

                            # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
                            if isinstance(jpeg_buf, np.ndarray):
                                # ì´ë¯¸ numpy arrayì¸ ê²½ìš° - flatten ë° uint8 ë³€í™˜
                                jpeg_array = jpeg_buf.flatten().astype(np.uint8)
                            elif isinstance(jpeg_buf, (bytes, bytearray)):
                                # bytesì¸ ê²½ìš° ë³€í™˜
                                jpeg_array = np.frombuffer(jpeg_buf, dtype=np.uint8)
                            else:
                                # ê¸°íƒ€ íƒ€ì… (ë¦¬ìŠ¤íŠ¸ ë“±)
                                jpeg_array = np.array(jpeg_buf, dtype=np.uint8).flatten()

                            # ë¹ˆ ë²„í¼ ì²´í¬
                            if jpeg_array.size == 0:
                                decode_failures += 1
                                decoded_frames.append(np.zeros((480, 640, 3), dtype=np.uint8))
                                continue

                            # OpenCVê°€ ìš”êµ¬í•˜ëŠ” í˜•ì‹ í™•ì¸: 1D contiguous uint8 array
                            if not jpeg_array.flags['C_CONTIGUOUS']:
                                jpeg_array = np.ascontiguousarray(jpeg_array)

                            # JPEG ë””ì½”ë”©: bytes â†’ BGR â†’ RGB
                            img_bgr = cv2.imdecode(jpeg_array, cv2.IMREAD_COLOR)

                            if img_bgr is not None and img_bgr.size > 0:
                                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                                decoded_frames.append(img_rgb)
                            else:
                                decode_failures += 1
                                # ë¹ˆ í”„ë ˆì„ ì¶”ê°€ (ì—ëŸ¬ ë°©ì§€)
                                decoded_frames.append(np.zeros((480, 640, 3), dtype=np.uint8))

                        except Exception as e:
                            decode_failures += 1
                            if idx < 5 or decode_failures < 5:  # ì²˜ìŒ ëª‡ ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                print(f"   âš ï¸ Error decoding {cam} frame {idx}: {e}")
                            decoded_frames.append(np.zeros((480, 640, 3), dtype=np.uint8))

                    video_streams[cam] = np.array(decoded_frames)
                    if decode_failures > 0:
                        print(f"   âš ï¸ {cam}: {decode_failures}/{len(decoded_frames)} frames failed decoding (replaced with black)")
                    else:
                        print(f"   âœ“ {cam}: {len(decoded_frames)} frames decoded")
            else:
                print("ğŸ”„ Detected GZIP compression format - Loading frames...")
                for cam in cam_keys:
                    # GZIP: ì´ë¯¸ ë””ì½”ë”©ëœ RGB ë°°ì—´
                    video_streams[cam] = images_grp[cam][:]
                    print(f"   âœ“ {cam}: {len(video_streams[cam])} frames loaded") 

            # --- 2. ë¹„ë””ì˜¤ ì¬ìƒ (OpenCV) ---
            print("\n=== â¯ï¸ Playback Controls ===")
            print(" [SPACE] Pause/Resume")
            print(" [Q]     Stop Video & Show Graphs")
            
            paused = False
            i = 0
            
            while i < total_steps:
                if not paused:
                    frames = []
                    for cam in cam_keys:
                        # RGB -> BGR
                        frame = cv2.cvtColor(video_streams[cam][i], cv2.COLOR_RGB2BGR)
                        cv2.putText(frame, f"{cam}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                        frames.append(frame)
                    
                    # í™”ë©´ ë³‘í•©
                    combined_img = np.hstack(frames)
                    
                    # ì •ë³´ì°½ (Info Board)
                    h, w, _ = combined_img.shape
                    info_board = np.zeros((100, w, 3), dtype=np.uint8)
                    
                    # í˜„ì¬ ìƒíƒœ í…ìŠ¤íŠ¸
                    curr_act = actions[i]
                    curr_q = qpos[i]
                    
                    # Actionì˜ XYZì™€ íšŒì „ê°’(RxRyRz)ì„ ë‚˜ëˆ ì„œ í‘œì‹œ
                    txt1 = f"Step: {i}/{total_steps}"
                    txt2 = f"Act(Move): {curr_act[:3].round(2)} | Act(Rot): {curr_act[3:].round(2)}"
                    txt3 = f"Joints: {curr_q.round(1)}"
                    
                    cv2.putText(info_board, txt1, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    cv2.putText(info_board, txt2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(info_board, txt3, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
                    
                    display = np.vstack([combined_img, info_board])
                    
                    # í•´ìƒë„ê°€ ë„ˆë¬´ í¬ë©´ ì¤„ì´ê¸°
                    if display.shape[1] > 1920:
                        display = cv2.resize(display, (0, 0), fx=0.6, fy=0.6)

                    cv2.imshow("Dataset Verification Player", display)
                    i += 1

                key = cv2.waitKey(33) # 30 FPS
                if key == ord('q'):
                    break
                elif key == ord(' '):
                    paused = not paused

            cv2.destroyAllWindows()
            print("ğŸ¬ Playback finished.")

            # --- 3. ê·¸ë˜í”„ ë¶„ì„ (Matplotlib) ---
            plot_detailed_data(actions, qpos, ee_pose)

    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ìë™ ë¡œë“œ
    dataset_dir = Path("./collected_data")
    files = sorted(dataset_dir.glob("*.h5"), key=lambda f: f.stat().st_mtime, reverse=True)
    
    if not files:
        print("âš ï¸ No dataset files (.h5) found!")
    else:
        play_and_inspect(files[0])