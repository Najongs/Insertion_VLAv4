# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ

Hugging Face Hubì—ì„œ í•™ìŠµëœ SmolVLA ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [Quick Start](#quick-start)
2. [Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©](#pythonì—ì„œ-ì§ì ‘-ì‚¬ìš©)
3. [Checkpoint í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ](#checkpoint-í˜•ì‹ìœ¼ë¡œ-ë‹¤ìš´ë¡œë“œ)
4. [ë‹¤ìš´ë¡œë“œ ì˜µì…˜](#ë‹¤ìš´ë¡œë“œ-ì˜µì…˜)

---

## Quick Start

### ë°©ë²• 1: Bash ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê°€ì¥ ê°„í¸)

```bash
# 1. ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •
nano download_model.sh

# REPO_IDë¥¼ ë‹¤ìš´ë¡œë“œí•  ëª¨ë¸ë¡œ ë³€ê²½:
REPO_ID="Najongs/smolvla-insertion-vla"

# 2. ì‹¤í–‰
bash download_model.sh
```

ëª¨ë¸ì´ `downloads/model/` ë””ë ‰í† ë¦¬ì— ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.

### ë°©ë²• 2: Python ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‚¬ìš©

```bash
python download_model.py \
    --repo_id "Najongs/smolvla-insertion-vla" \
    --output_dir "downloads/my_model" \
    --save_checkpoint
```

---

## Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©

ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ Python ì½”ë“œì—ì„œ ì§ì ‘ ë¡œë“œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

```python
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
import torch

# Hugging Face Hubì—ì„œ ëª¨ë¸ ë¡œë“œ
model_id = "Najongs/smolvla-insertion-vla"
policy = SmolVLAPolicy.from_pretrained(model_id)
policy.eval()

# GPUë¡œ ì´ë™
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
policy.to(device)

# Inference
with torch.no_grad():
    action = policy.select_action(observation)

print(f"Predicted action: {action}")
```

ì´ ë°©ë²•ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ìºì‹œì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤ (ë³´í†µ `~/.cache/huggingface/hub/`).

---

## Checkpoint í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ

Training ìŠ¤í¬ë¦½íŠ¸ì™€ í˜¸í™˜ë˜ëŠ” checkpoint í˜•ì‹(.pt)ìœ¼ë¡œë„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë°©ë²• 1: ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
python download_model.py \
    --repo_id "username/model-name" \
    --output_dir "downloads/model" \
    --save_checkpoint \
    --checkpoint_path "checkpoints/downloaded_model.pt"
```

### ë°©ë²• 2: Python ì½”ë“œ

```python
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
import torch

# ëª¨ë¸ ë¡œë“œ
policy = SmolVLAPolicy.from_pretrained("username/model-name")

# Checkpointë¡œ ì €ì¥
checkpoint = {
    "policy_state_dict": policy.state_dict(),
    "config": {
        "policy": {
            "pretrained_model_id": "username/model-name",
            "n_obs_steps": policy.config.n_obs_steps,
            "chunk_size": policy.config.chunk_size,
            "n_action_steps": policy.config.n_action_steps,
        }
    },
    "step": getattr(policy.config, "training_step", 0),
    "epoch": getattr(policy.config, "training_epoch", 0),
}

torch.save(checkpoint, "downloaded_model.pt")
print("Checkpoint saved!")
```

---

## ë‹¤ìš´ë¡œë“œ ì˜µì…˜

### ê¸°ë³¸ ë‹¤ìš´ë¡œë“œ

```bash
python download_model.py \
    --repo_id "username/model-name"
```

ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜: `downloads/model/`

### ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •

```bash
python download_model.py \
    --repo_id "username/model-name" \
    --output_dir "my_models/smolvla_v1"
```

### Checkpoint í˜•ì‹ìœ¼ë¡œ ì €ì¥

```bash
python download_model.py \
    --repo_id "username/model-name" \
    --save_checkpoint
```

ëª¨ë¸ê³¼ checkpoint ëª¨ë‘ ì €ì¥ë¨:
- `downloads/model/` - Hugging Face í˜•ì‹
- `downloads/model/checkpoint.pt` - PyTorch checkpoint

### íŠ¹ì • ë²„ì „/ë¸Œëœì¹˜ ë‹¤ìš´ë¡œë“œ

```bash
python download_model.py \
    --repo_id "username/model-name" \
    --revision "main"  # ë˜ëŠ” íŠ¹ì • commit hash
```

### ë¹„ê³µê°œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ í† í° ì„¤ì •
export HF_TOKEN="hf_your_token_here"

python download_model.py \
    --repo_id "username/private-model" \
    --token "$HF_TOKEN"
```

ë˜ëŠ” í† í°ì„ ì§ì ‘ ì „ë‹¬:

```bash
python download_model.py \
    --repo_id "username/private-model" \
    --token "hf_your_token_here"
```

---

## ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ

### 1. Inference ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

```python
# inference_script.py
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
import torch

# ë‹¤ìš´ë¡œë“œí•œ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
model_path = "downloads/model"
policy = SmolVLAPolicy.from_pretrained(model_path)
policy.eval()

# ë˜ëŠ” Hubì—ì„œ ì§ì ‘ ë¡œë“œ
policy = SmolVLAPolicy.from_pretrained("username/model-name")
policy.eval()

# Inference
device = torch.device("cuda")
policy.to(device)

observation = {
    "observation.images.camera1": image_tensor,
    "observation.state": state_tensor,
    "task": "Insert needle into Red point",
    "robot_type": "meca500",
}

with torch.no_grad():
    action = policy.select_action(observation)
```

### 2. Fine-tuningì„ ìœ„í•œ Checkpoint ë¡œë“œ

```python
import torch
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# Checkpoint ë¡œë“œ
checkpoint = torch.load("downloads/model/checkpoint.pt")
policy_state_dict = checkpoint["policy_state_dict"]
config = checkpoint["config"]["policy"]

# ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
policy = SmolVLAPolicy.from_pretrained(config["pretrained_model_id"])
policy.load_state_dict(policy_state_dict, strict=False)

# Fine-tuning ì‹œì‘
optimizer = torch.optim.AdamW(policy.parameters(), lr=1e-5)
# ... training code
```

### 3. ëª¨ë¸ ë¹„êµ

ì—¬ëŸ¬ ë²„ì „ì˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¹„êµ:

```bash
# ë²„ì „ 1 ë‹¤ìš´ë¡œë“œ
python download_model.py \
    --repo_id "username/model-v1" \
    --output_dir "models/v1" \
    --save_checkpoint

# ë²„ì „ 2 ë‹¤ìš´ë¡œë“œ
python download_model.py \
    --repo_id "username/model-v2" \
    --output_dir "models/v2" \
    --save_checkpoint

# í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë¹„êµ
python compare_models.py \
    --models models/v1 models/v2 \
    --dataset eval_data
```

---

## ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ ì •ë³´ í™•ì¸

```python
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# ëª¨ë¸ ë¡œë“œ
policy = SmolVLAPolicy.from_pretrained("downloads/model")

# Config ì •ë³´
print(f"Observation steps: {policy.config.n_obs_steps}")
print(f"Chunk size: {policy.config.chunk_size}")
print(f"Action steps: {policy.config.n_action_steps}")

# ëª¨ë¸ í¬ê¸°
total_params = sum(p.numel() for p in policy.parameters())
print(f"Total parameters: {total_params:,}")

# Training ì •ë³´ (ìˆëŠ” ê²½ìš°)
if hasattr(policy.config, "training_step"):
    print(f"Training step: {policy.config.training_step}")
if hasattr(policy.config, "training_epoch"):
    print(f"Training epoch: {policy.config.training_epoch}")
```

---

## ìºì‹œ ê´€ë¦¬

Hugging Face HubëŠ” ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ìºì‹œí•©ë‹ˆë‹¤.

### ìºì‹œ ìœ„ì¹˜ í™•ì¸

```bash
echo $HF_HOME
# ê¸°ë³¸ê°’: ~/.cache/huggingface/
```

### ìºì‹œ ì‚­ì œ

```bash
# íŠ¹ì • ëª¨ë¸ ìºì‹œ ì‚­ì œ
rm -rf ~/.cache/huggingface/hub/models--username--model-name

# ì „ì²´ ìºì‹œ ì‚­ì œ (ì£¼ì˜!)
rm -rf ~/.cache/huggingface/hub/
```

### ìºì‹œ ë””ë ‰í† ë¦¬ ë³€ê²½

```bash
export HF_HOME="/path/to/custom/cache"
python download_model.py --repo_id "username/model"
```

---

## ë¬¸ì œ í•´ê²°

### Q: "Repository not found" ì˜¤ë¥˜

**ì›ì¸:** Repositoryê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ê³µê°œ

**í•´ê²°:**
1. Repository IDê°€ ì •í™•í•œì§€ í™•ì¸
2. ë¹„ê³µê°œ ëª¨ë¸ì¸ ê²½ìš° í† í° ì„¤ì •:
   ```bash
   export HF_TOKEN="hf_your_token"
   ```

### Q: ë‹¤ìš´ë¡œë“œê°€ ì¤‘ë‹¨ë¨

**ì›ì¸:** ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ

**í•´ê²°:**
- ì¬ì‹œë„ (ìºì‹œê°€ ìˆì–´ì„œ ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œë¨)
- ì•ˆì •ì ì¸ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©

### Q: "Out of disk space" ì˜¤ë¥˜

**ì›ì¸:** ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**í•´ê²°:**
- ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: `df -h`
- ë¶ˆí•„ìš”í•œ ìºì‹œ ì‚­ì œ
- ë‹¤ë¥¸ ë””ìŠ¤í¬ë¡œ ìºì‹œ ìœ„ì¹˜ ë³€ê²½

### Q: Git LFS ì˜¤ë¥˜

**ì›ì¸:** Git LFSê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°:**
```bash
# Ubuntu/Debian
sudo apt-get install git-lfs

# macOS
brew install git-lfs

# ì„¤ì¹˜ í›„
git lfs install
```

---

## ì˜¤í”„ë¼ì¸ ì‚¬ìš©

ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ì˜¤í”„ë¼ì¸ì—ì„œ ì‚¬ìš©:

```python
# 1. ì˜¨ë¼ì¸ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
policy = SmolVLAPolicy.from_pretrained("username/model")
policy.save_pretrained("my_offline_model")

# 2. ì˜¤í”„ë¼ì¸ì—ì„œ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
policy = SmolVLAPolicy.from_pretrained("my_offline_model", local_files_only=True)
```

---

## ëª¨ë¸ ê³µìœ 

ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì„ ë‹¤ë¥¸ ì‚¬ëŒê³¼ ê³µìœ :

### ë°©ë²• 1: ë¡œì»¬ íŒŒì¼ ê³µìœ 

```bash
# ëª¨ë¸ ë””ë ‰í† ë¦¬ ì••ì¶•
tar -czf smolvla_model.tar.gz downloads/model/

# ì „ì†¡ í›„ ì••ì¶• í•´ì œ
tar -xzf smolvla_model.tar.gz

# ì‚¬ìš©
python -c "
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
policy = SmolVLAPolicy.from_pretrained('downloads/model')
"
```

### ë°©ë²• 2: ì¬ì—…ë¡œë“œ

```bash
# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì„ ë‹¤ë¥¸ Repositoryì— ì—…ë¡œë“œ
python upload_to_huggingface.py \
    --checkpoint downloads/model/checkpoint.pt \
    --repo_id "new-username/model-copy"
```

---

## ì°¸ê³  ìë£Œ

- [Hugging Face Hub ë¬¸ì„œ](https://huggingface.co/docs/hub/)
- [Transformers ëª¨ë¸ ë¡œë”©](https://huggingface.co/docs/transformers/main/model_sharing)
- [LeRobot ë¬¸ì„œ](https://github.com/huggingface/lerobot)

---

## ë‹¤ìŒ ë‹¨ê³„

ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„:

1. Inference ìŠ¤í¬ë¦½íŠ¸ì— í†µí•©
2. ë¡œë´‡ ì œì–´ ì‹œìŠ¤í…œê³¼ ì—°ê²°
3. Fine-tuning ì§„í–‰
4. ì„±ëŠ¥ í‰ê°€

ë” ìì„¸í•œ ë‚´ìš©ì€ [README.md](README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
